log_root: 'logs'
seed: 42
dist_timeout: 2400
telegram_reports: True
fp16: False

dataset:
  num_workers: 8
  num_workers_val: 8
  name: 'spoofing_combined_2023'
  root: '~/datasets/spoofing_2023/'
  resize_size: 232
  crop_size: 224
  smoothing: True
  augmentation: 'medium2'
  train_set:
    - datasets/spoofing/ds1_train/markup.csv
    - datasets/spoofing/ds2_train/

  val_set:
    - datasets/spoofing/ds1_val/markup.csv
    - datasets/spoofing/ds2_val/


model:
  base: 'efficientformerv2_s0'
  pretrained: True  # Attempt to load ImageNet pretrained weights
  checkpoint_path: ""
  resume: False
  resume_strict: True
  dropout: 0.1
  drop_path_rate: 0.1
  descriptor_size: 512  # The last layer size before the classification layer
  num_prototypes: 4
  num_classes: 2

train:
  val_before_train: True
  batch_size: 128
  optimizer: 'adamw'
  lr: 0.0002
  weight_decay: 0.00005
  num_epochs: 3000
  scheduler_name: cosr
  restart_epoch: 10  # for CosineAnnealingWarmRestarts
  restart_multiplier: 2  # for CosineAnnealingWarmRestarts
  load_optimizer: False
  load_scheduler: False
  balanced_sampler: True

loss:
  inter_delta: 0.258
  intra_delta: 0.966
  scale: 2
  margin: 0.25
  inter_weight: 0.01
  intra_weight: 0.01
  data_weight: 0.01

val:
  batch_size: 1024